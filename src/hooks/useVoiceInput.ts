"use client";

import { useState, useCallback, useEffect, useRef } from "react";

// Rozszerzenie typ贸w dla Web Speech API
interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
  resultIndex: number;
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
  message?: string;
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  start(): void;
  stop(): void;
  abort(): void;
  onresult: ((event: SpeechRecognitionEvent) => void) | null;
  onerror: ((event: SpeechRecognitionErrorEvent) => void) | null;
  onend: (() => void) | null;
  onstart: (() => void) | null;
}

declare global {
  interface Window {
    SpeechRecognition: new () => SpeechRecognition;
    webkitSpeechRecognition: new () => SpeechRecognition;
  }
}

export type VoiceInputState = "idle" | "listening" | "processing";

interface UseVoiceInputOptions {
  /** Jzyk rozpoznawania mowy (domylnie pl-PL) */
  language?: string;
  /** Czy automatycznie wysya po zakoczeniu m贸wienia */
  autoSend?: boolean;
  /** Callback gdy tekst jest rozpoznany */
  onTranscript?: (text: string) => void;
  /** Callback do wysania wiadomoci */
  onSend?: (text: string) => void;
  /** Czas ciszy po kt贸rym koczy si nagrywanie (ms) */
  silenceTimeout?: number;
}

interface UseVoiceInputReturn {
  /** Stan nagrywania */
  state: VoiceInputState;
  /** Czy przegldarka wspiera Web Speech API */
  isSupported: boolean;
  /** Tymczasowy transkrypt (podczas m贸wienia) */
  interimTranscript: string;
  /** Kocowy transkrypt */
  finalTranscript: string;
  /** Komunikat bdu */
  error: string | null;
  /** Rozpocznij nagrywanie */
  startListening: () => void;
  /** Zatrzymaj nagrywanie */
  stopListening: () => void;
  /** Przecz nagrywanie */
  toggleListening: () => void;
}

/**
 * Hook do obsugi voice input z Web Speech API
 */
export function useVoiceInput(
  options: UseVoiceInputOptions = {}
): UseVoiceInputReturn {
  const {
    language = "pl-PL",
    autoSend = true,
    onTranscript,
    onSend,
    silenceTimeout = 1500,
  } = options;

  const [state, setState] = useState<VoiceInputState>("idle");
  const [isSupported, setIsSupported] = useState(false);
  const [interimTranscript, setInterimTranscript] = useState("");
  const [finalTranscript, setFinalTranscript] = useState("");
  const [error, setError] = useState<string | null>(null);

  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const silenceTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const finalTranscriptRef = useRef("");

  // Sprawd藕 wsparcie dla Web Speech API
  useEffect(() => {
    if (typeof window !== "undefined") {
      const SpeechRecognitionAPI =
        window.SpeechRecognition || window.webkitSpeechRecognition;
      setIsSupported(!!SpeechRecognitionAPI);
    }
  }, []);

  // Cleanup przy unmount
  useEffect(() => {
    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.abort();
      }
      if (silenceTimeoutRef.current) {
        clearTimeout(silenceTimeoutRef.current);
      }
    };
  }, []);

  const startListening = useCallback(async () => {
    if (!isSupported) {
      setError("Twoja przegldarka nie wspiera rozpoznawania mowy");
      return;
    }

    // Test czy mikrofon w og贸le dziaa
    try {
      console.log("Testing microphone access...");
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      console.log("Microphone access OK, stopping stream...");
      stream.getTracks().forEach((track) => track.stop());
    } catch (e) {
      console.error("getUserMedia failed:", e);
      setError("Nie mo偶na uzyska dostpu do mikrofonu. Sprawd藕 ustawienia.");
      return;
    }

    setError(null);
    setInterimTranscript("");
    setFinalTranscript("");
    finalTranscriptRef.current = "";

    const SpeechRecognitionAPI =
      window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognitionAPI();

    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = language;

    recognition.onstart = () => {
      console.log(" Speech recognition started");
      setState("listening");
    };

    recognition.onresult = (event: SpeechRecognitionEvent) => {
      console.log(" Speech result received:", event.results);
      let interim = "";
      let final = "";

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i];
        const transcript = result[0].transcript;
        console.log(`  Result ${i}: "${transcript}", isFinal: ${result.isFinal}`);

        if (result.isFinal) {
          final += transcript;
        } else {
          interim += transcript;
        }
      }

      console.log(`  Interim: "${interim}", Final: "${final}"`);

      if (final) {
        finalTranscriptRef.current += final;
        setFinalTranscript(finalTranscriptRef.current);
        console.log("  Calling onTranscript with:", finalTranscriptRef.current);
        onTranscript?.(finalTranscriptRef.current);
      }

      setInterimTranscript(interim);

      // Reset silence timeout
      if (silenceTimeoutRef.current) {
        clearTimeout(silenceTimeoutRef.current);
      }

      // Set new silence timeout
      if (autoSend && finalTranscriptRef.current) {
        silenceTimeoutRef.current = setTimeout(() => {
          if (finalTranscriptRef.current.trim()) {
            setState("processing");
            onSend?.(finalTranscriptRef.current.trim());
            recognition.stop();
          }
        }, silenceTimeout);
      }
    };

    recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
      console.error("Speech recognition error:", event.error);

      switch (event.error) {
        case "no-speech":
          setError("Nie wykryto mowy. Spr贸buj ponownie.");
          break;
        case "audio-capture":
          setError("Brak dostpu do mikrofonu.");
          break;
        case "not-allowed":
          setError(
            "Dostp do mikrofonu zosta zablokowany. Kliknij ikon k贸dki w pasku adresu, aby zmieni ustawienia."
          );
          break;
        case "network":
          setError("Bd sieci. Sprawd藕 poczenie.");
          break;
        default:
          setError("Wystpi bd podczas rozpoznawania mowy.");
      }

      setState("idle");
    };

    recognition.onend = () => {
      if (silenceTimeoutRef.current) {
        clearTimeout(silenceTimeoutRef.current);
      }

      // Jeli jest transkrypt i nie by wysany automatycznie
      if (
        !autoSend &&
        finalTranscriptRef.current.trim() &&
        state === "listening"
      ) {
        onTranscript?.(finalTranscriptRef.current.trim());
      }

      setState("idle");
      recognitionRef.current = null;
    };

    recognitionRef.current = recognition;

    try {
      recognition.start();
    } catch (e) {
      console.error("Failed to start speech recognition:", e);
      setError("Nie udao si uruchomi rozpoznawania mowy.");
      setState("idle");
    }
  }, [isSupported, language, autoSend, onTranscript, onSend, silenceTimeout, state]);

  const stopListening = useCallback(() => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
    }

    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current);
    }

    // Jeli jest transkrypt, wylij go
    if (autoSend && finalTranscriptRef.current.trim()) {
      setState("processing");
      onSend?.(finalTranscriptRef.current.trim());
    }

    setState("idle");
  }, [autoSend, onSend]);

  const toggleListening = useCallback(() => {
    if (state === "listening") {
      stopListening();
    } else if (state === "idle") {
      startListening();
    }
  }, [state, startListening, stopListening]);

  return {
    state,
    isSupported,
    interimTranscript,
    finalTranscript,
    error,
    startListening,
    stopListening,
    toggleListening,
  };
}

